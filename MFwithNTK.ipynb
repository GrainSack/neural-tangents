{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPihuzAqMj3H7u0dTqBg4Mz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GrainSack/neural-tangents/blob/main/MFwithNTK.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7Zk7Ni-yxq7",
        "outputId": "8147b82a-67e9-4831-a25c-519918719f82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Neural_CF-master"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNpsFWYZy0Gn",
        "outputId": "6dbff3a2-5664-443f-f3e1-b9d1284af787"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Neural_CF-master\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.core.display import display, HTML\n",
        "display(HTML(\"<style>.container { width: 75% !important; }</style>\"))\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "WtoE56JEzA4C",
        "outputId": "125e7d7e-c703-4e21-93bd-0b8e45ebdd76"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>.container { width: 75% !important; }</style>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from google.colab import files\n",
        "#uploaded = files.upload()"
      ],
      "metadata": {
        "id": "bwPihRr_2e6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/drive/MyDrive/Neural_CF-master/lastfm-dataset-360K'\n",
        "df = pd.read_csv(file_path + '/usersha1-artmbid-artname-plays.tsv', delimiter='\\t', header=None)\n",
        "\n",
        "df = df.drop(df.columns[2], axis=1)\n",
        "df.columns = ['user', 'item', 'plays']\n",
        "df = df.dropna()\n",
        "df = df.loc[df.plays != 0]"
      ],
      "metadata": {
        "id": "ng9afmaszyQv"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYm94xyp2D2e",
        "outputId": "9c70d20b-9852-446e-9acd-7f79ddb8c23f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(17309518, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "F6BGwcIb_DbN",
        "outputId": "5f59bc6a-86b8-4792-855c-89881d841c7e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                       user  \\\n",
              "0  00000c289a1829a808ac09c00daf10bc3c4e223b   \n",
              "1  00000c289a1829a808ac09c00daf10bc3c4e223b   \n",
              "2  00000c289a1829a808ac09c00daf10bc3c4e223b   \n",
              "3  00000c289a1829a808ac09c00daf10bc3c4e223b   \n",
              "4  00000c289a1829a808ac09c00daf10bc3c4e223b   \n",
              "\n",
              "                                   item  plays  \n",
              "0  3bd73256-3905-4f3a-97e2-8b341527f805   2137  \n",
              "1  f2fb0ff0-5679-42ec-a55c-15109ce6e320   1099  \n",
              "2  b3ae82c2-e60b-4551-a76d-6620f1b456aa    897  \n",
              "3  3d6bbeb7-f90e-4d10-b440-e153c0d10b53    717  \n",
              "4  bbd2ffd7-17f4-4506-8572-c1ea58c3f9a8    706  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-60f03850-4f9f-4e41-b864-4db24cc9e46c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user</th>\n",
              "      <th>item</th>\n",
              "      <th>plays</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00000c289a1829a808ac09c00daf10bc3c4e223b</td>\n",
              "      <td>3bd73256-3905-4f3a-97e2-8b341527f805</td>\n",
              "      <td>2137</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>00000c289a1829a808ac09c00daf10bc3c4e223b</td>\n",
              "      <td>f2fb0ff0-5679-42ec-a55c-15109ce6e320</td>\n",
              "      <td>1099</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00000c289a1829a808ac09c00daf10bc3c4e223b</td>\n",
              "      <td>b3ae82c2-e60b-4551-a76d-6620f1b456aa</td>\n",
              "      <td>897</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>00000c289a1829a808ac09c00daf10bc3c4e223b</td>\n",
              "      <td>3d6bbeb7-f90e-4d10-b440-e153c0d10b53</td>\n",
              "      <td>717</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>00000c289a1829a808ac09c00daf10bc3c4e223b</td>\n",
              "      <td>bbd2ffd7-17f4-4506-8572-c1ea58c3f9a8</td>\n",
              "      <td>706</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-60f03850-4f9f-4e41-b864-4db24cc9e46c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-60f03850-4f9f-4e41-b864-4db24cc9e46c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-60f03850-4f9f-4e41-b864-4db24cc9e46c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('user 수:', len(np.unique(list(df['user'])))) \n",
        "print('artist 수:', len(np.unique(list(df['item']))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9gWIMqA_Fp0",
        "outputId": "3315573c-178b-45ba-9301-85604011e643"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "user 수: 358858\n",
            "artist 수: 160112\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_analy_dataset(df):\n",
        "    \"\"\"\n",
        "    데이터 로드 함수 \n",
        "    \n",
        "    uids: train user\n",
        "    iids: train item\n",
        "    users: 전체 user          \n",
        "    items: 전체 item\n",
        "    df_train: train data\n",
        "    df_test: test data\n",
        "    \"\"\"\n",
        "    # user 10000명 샘플링 \n",
        "    unique_user_lst = list(np.unique(df['user'])) #358857명 \n",
        "    sample_user_idx = np.random.choice(len(unique_user_lst), 10000, replace=False)\n",
        "    sample_user_lst = [unique_user_lst[idx] for idx in sample_user_idx]\n",
        "    \n",
        "    df = df[df['user'].isin(sample_user_lst)]\n",
        "    df = df.reset_index(drop=True)\n",
        "\n",
        "    # 1명 이상의 artist데이터가 있는 user만 사용 \n",
        "    df_count = df.groupby(['user']).count()\n",
        "    df['count'] = df.groupby('user')['user'].transform('count')\n",
        "    df = df[df['count'] > 1]\n",
        "\n",
        "    # user, item 아이디 부여 \n",
        "    df['user_id'] = df['user'].astype(\"category\").cat.codes\n",
        "    df['item_id'] = df['item'].astype(\"category\").cat.codes\n",
        "\n",
        "    # lookup 테이블 생성 \n",
        "    item_lookup = df[['item_id', 'item']].drop_duplicates()\n",
        "    item_lookup['item_id'] = item_lookup.item_id.astype(str)\n",
        "\n",
        "    # train, test 데이터 생성 \n",
        "    df = df[['user_id', 'item_id', 'plays']] \n",
        "    df_train, df_test = train_test_split(df)\n",
        "\n",
        "    # 전체 user, item 리스트 생성 \n",
        "    users = list(np.sort(df.user_id.unique())) \n",
        "    items = list(np.sort(df.item_id.unique())) \n",
        "\n",
        "    # train user, item 리스트 생성 \n",
        "    rows = df_train['user_id'].astype(int)   \n",
        "    cols = df_train['item_id'].astype(int)\n",
        "    values = list(df_train.plays) \n",
        "    \n",
        "    uids = np.array(rows.tolist())\n",
        "    iids = np.array(cols.tolist())\n",
        "\n",
        "    # 각 user마다 negative item 생성 \n",
        "    df_neg = get_negatives(uids, iids, items, df_test)\n",
        "\n",
        "    return uids, iids, df_train, df_test, df_neg, users, items, item_lookup\n",
        "\n",
        "def get_negatives(uids, iids, items, df_test):\n",
        "    \"\"\"\n",
        "    negative item 리스트 생성함수\n",
        "    \"\"\"\n",
        "    negativeList = []\n",
        "    test_u = df_test['user_id'].values.tolist() \n",
        "    test_i = df_test['item_id'].values.tolist() \n",
        " \n",
        "    test_ratings = list(zip(test_u, test_i)) # test (user, item)세트 \n",
        "    zipped = set(zip(uids, iids))            # train (user, item)세트\n",
        "\n",
        "    for (u, i) in test_ratings:\n",
        "        \n",
        "        negatives = []\n",
        "        negatives.append((u, i))\n",
        "        for t in range(100):\n",
        "            j = np.random.randint(len(items))     # neg_item j 1개 샘플링 \n",
        "            while (u, j) in zipped:               # j가 train에 있으면 다시뽑고, 없으면 선택 \n",
        "                j = np.random.randint(len(items)) \n",
        "            negatives.append(j)\n",
        "        negativeList.append(negatives) # [(0,pos), neg, neg, ...]\n",
        "\n",
        "    df_neg = pd.DataFrame(negativeList)\n",
        "\n",
        "    return df_neg\n",
        "\n",
        "def mask_first(x):\n",
        "\n",
        "    result = np.ones_like(x) \n",
        "    result[0] = 0  # [0,1,1,....]\n",
        "    \n",
        "    return result\n",
        "\n",
        "def train_test_split(df):\n",
        "    \"\"\"\n",
        "    train, test 나누는 함수\n",
        "    \"\"\"\n",
        "    df_test = df.copy(deep=True)\n",
        "    df_train = df.copy(deep=True)\n",
        "    \n",
        "    # df_test\n",
        "    # user_id와 holdout_item_id(user가 플레이한 아이템 중 1개)뽑기 \n",
        "    df_test = df_test.groupby(['user_id']).first() \n",
        "    df_test['user_id'] = df_test.index\n",
        "    df_test = df_test[['user_id', 'item_id', 'plays']]\n",
        "    df_test = df_test.reset_index(drop=True)\n",
        "    \n",
        "    # df_train \n",
        "    # user_id 리스트에 make_first()적용 \n",
        "    mask = df.groupby(['user_id'])['user_id'].transform(mask_first).astype(bool)\n",
        "    df_train = df.loc[mask]  \n",
        "\n",
        "    return df_train, df_test\n",
        "\n",
        "def get_train_instances(uids, iids, num_neg, num_items):\n",
        "    \"\"\"\n",
        "    모델에 사용할 train 데이터 생성 함수 \n",
        "    \"\"\"\n",
        "    user_input, item_input, labels = [],[],[]\n",
        "    zipped = set(zip(uids, iids)) # train (user, item) 세트\n",
        "\n",
        "    for (u, i) in zip(uids, iids):\n",
        "        \n",
        "        # pos item 추가 \n",
        "        user_input.append(u) #[u]\n",
        "        item_input.append(i) #[pos_i]\n",
        "        labels.append(1)     #[1]\n",
        "\n",
        "        # neg item 추가 \n",
        "        for t in range(num_neg):\n",
        "            \n",
        "            j = np.random.randint(num_items)     # neg_item j num_neg(4)개 샘플링\n",
        "            while (u, j) in zipped:              # u가 j를 이미 선택했다면 \n",
        "                j = np.random.randint(num_items) # 다시 샘플링 \n",
        "                \n",
        "            user_input.append(u) # [u1, u1,  u1,  ...]\n",
        "            item_input.append(j) # [pos_i, neg_j1, neg_j2, ...]\n",
        "            labels.append(0)     # [1, 0,  0,  ...]\n",
        "\n",
        "    return user_input, item_input, labels"
      ],
      "metadata": {
        "id": "IdiIxmAf_Hd2"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uids, iids, df_train, df_test, df_neg, users, items, item_lookup = prepare_analy_dataset(df)"
      ],
      "metadata": {
        "id": "wC-88Y88_KIo"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "iXuD6r_z_LsN",
        "outputId": "fb6ae19b-5017-45b6-acda-10a13ed9589f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    user_id  item_id  plays\n",
              "1         0    32117   1540\n",
              "2         0     7898   1403\n",
              "3         0    15735   1308\n",
              "4         0     4388   1214\n",
              "5         0     5478   1197\n",
              "6         0     3822    945\n",
              "7         0    44460    895\n",
              "8         0    47358    887\n",
              "9         0     3912    833\n",
              "10        0     7939    721"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a0bb1ad3-2939-467b-a217-9679278328ae\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>item_id</th>\n",
              "      <th>plays</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>32117</td>\n",
              "      <td>1540</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>7898</td>\n",
              "      <td>1403</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>15735</td>\n",
              "      <td>1308</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>4388</td>\n",
              "      <td>1214</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>5478</td>\n",
              "      <td>1197</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>3822</td>\n",
              "      <td>945</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>44460</td>\n",
              "      <td>895</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0</td>\n",
              "      <td>47358</td>\n",
              "      <td>887</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0</td>\n",
              "      <td>3912</td>\n",
              "      <td>833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0</td>\n",
              "      <td>7939</td>\n",
              "      <td>721</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a0bb1ad3-2939-467b-a217-9679278328ae')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a0bb1ad3-2939-467b-a217-9679278328ae button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a0bb1ad3-2939-467b-a217-9679278328ae');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kuzF7NJb_M8Q",
        "outputId": "e661f68a-f7f1-4a36-ba59-6dcf2f79a1fe"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(472097, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_input, item_input, labels = get_train_instances(uids, iids, num_neg=4, num_items=len(items))"
      ],
      "metadata": {
        "id": "EgmeZ3s6_Ohq"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('df_train의 첫번째 행: (user_id, item_id)=', (uids[0], iids[0])) \n",
        "print('df_train의 두번째 행: (user_id, item_id)=', (uids[1], iids[1])) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EU9Zcv24_P4O",
        "outputId": "9fa2d263-c64a-4ede-a4fc-b332ddfcf576"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "df_train의 첫번째 행: (user_id, item_id)= (0, 32117)\n",
            "df_train의 두번째 행: (user_id, item_id)= (0, 7898)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, (user_id, item_id, label) in enumerate(zip(user_input[0:10], item_input[0:10], labels[0:10])):\n",
        "    if i==0 or i==5:\n",
        "        print('(user_id, postive_item_id, label):', (user_id, item_id, label))\n",
        "    else:\n",
        "        print('(user_id, negative_item_id, label):', (user_id, item_id, label))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zf_iUN2D_RYQ",
        "outputId": "1594dbbb-baab-43fd-b377-0ec6e9d095f9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(user_id, postive_item_id, label): (0, 32117, 1)\n",
            "(user_id, negative_item_id, label): (0, 16826, 0)\n",
            "(user_id, negative_item_id, label): (0, 38790, 0)\n",
            "(user_id, negative_item_id, label): (0, 40056, 0)\n",
            "(user_id, negative_item_id, label): (0, 36382, 0)\n",
            "(user_id, postive_item_id, label): (0, 7898, 1)\n",
            "(user_id, negative_item_id, label): (0, 4910, 0)\n",
            "(user_id, negative_item_id, label): (0, 28710, 0)\n",
            "(user_id, negative_item_id, label): (0, 30522, 0)\n",
            "(user_id, negative_item_id, label): (0, 36932, 0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "WfZqfyYg_SzM",
        "outputId": "f45469af-3c6a-4630-bec5-555a16f511b7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   user_id  item_id  plays\n",
              "0        0    40780   2618\n",
              "1        1    15453    744\n",
              "2        2    37624    157\n",
              "3        3    33130    802\n",
              "4        4    25257    341\n",
              "5        5    21499    835\n",
              "6        6     1227   1046\n",
              "7        7    11773   4418\n",
              "8        8     2215    168\n",
              "9        9    30763   1776"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9b0f3f43-600d-4f61-8ecd-273a1828b59f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>item_id</th>\n",
              "      <th>plays</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>40780</td>\n",
              "      <td>2618</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>15453</td>\n",
              "      <td>744</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>37624</td>\n",
              "      <td>157</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>33130</td>\n",
              "      <td>802</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>25257</td>\n",
              "      <td>341</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>21499</td>\n",
              "      <td>835</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>1227</td>\n",
              "      <td>1046</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>11773</td>\n",
              "      <td>4418</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>2215</td>\n",
              "      <td>168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>30763</td>\n",
              "      <td>1776</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9b0f3f43-600d-4f61-8ecd-273a1828b59f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9b0f3f43-600d-4f61-8ecd-273a1828b59f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9b0f3f43-600d-4f61-8ecd-273a1828b59f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j61x3cNs_UP0",
        "outputId": "6a2b618b-cddd-48d7-ea04-e7b7cd7b9ac5"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9997, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_neg.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "tQzFKBHo_VXn",
        "outputId": "c80ae288-b566-4f63-c485-59ba654ddd3d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          0      1      2      3      4      5      6      7      8      9    \\\n",
              "0  (0, 40780)  18447  14159  44985  43226  12988  38499  40761  18261  14179   \n",
              "1  (1, 15453)  37389  38644   6809  10012  45516  12896   3300   1927  30358   \n",
              "2  (2, 37624)  32649   5050  34405  48404  43756  19581   1985  36912  28457   \n",
              "3  (3, 33130)   7706  24412  18241  38745  43345  38608  43129  44668   2578   \n",
              "4  (4, 25257)  24924   9387  36992   5516  30135  10238  40738  44509   5677   \n",
              "\n",
              "   ...    91     92     93     94     95     96     97     98     99     100  \n",
              "0  ...  24176  25296    421  37182  47583  11273  17766  10523   9190  41012  \n",
              "1  ...   6337  38598   1264  24409  47353  44961   1350    136  36001  38596  \n",
              "2  ...  39536   7744  13616  11921   1140  24986   8178  19577  37338  18657  \n",
              "3  ...  14984  36433  10382  13264  42512  37398  28594  16568  23680   1532  \n",
              "4  ...   4496  26082   2747  15780  23746   8108  31261  20875    368  47955  \n",
              "\n",
              "[5 rows x 101 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dc116bb0-6952-4171-be25-9d61cddc35cd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>91</th>\n",
              "      <th>92</th>\n",
              "      <th>93</th>\n",
              "      <th>94</th>\n",
              "      <th>95</th>\n",
              "      <th>96</th>\n",
              "      <th>97</th>\n",
              "      <th>98</th>\n",
              "      <th>99</th>\n",
              "      <th>100</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>(0, 40780)</td>\n",
              "      <td>18447</td>\n",
              "      <td>14159</td>\n",
              "      <td>44985</td>\n",
              "      <td>43226</td>\n",
              "      <td>12988</td>\n",
              "      <td>38499</td>\n",
              "      <td>40761</td>\n",
              "      <td>18261</td>\n",
              "      <td>14179</td>\n",
              "      <td>...</td>\n",
              "      <td>24176</td>\n",
              "      <td>25296</td>\n",
              "      <td>421</td>\n",
              "      <td>37182</td>\n",
              "      <td>47583</td>\n",
              "      <td>11273</td>\n",
              "      <td>17766</td>\n",
              "      <td>10523</td>\n",
              "      <td>9190</td>\n",
              "      <td>41012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>(1, 15453)</td>\n",
              "      <td>37389</td>\n",
              "      <td>38644</td>\n",
              "      <td>6809</td>\n",
              "      <td>10012</td>\n",
              "      <td>45516</td>\n",
              "      <td>12896</td>\n",
              "      <td>3300</td>\n",
              "      <td>1927</td>\n",
              "      <td>30358</td>\n",
              "      <td>...</td>\n",
              "      <td>6337</td>\n",
              "      <td>38598</td>\n",
              "      <td>1264</td>\n",
              "      <td>24409</td>\n",
              "      <td>47353</td>\n",
              "      <td>44961</td>\n",
              "      <td>1350</td>\n",
              "      <td>136</td>\n",
              "      <td>36001</td>\n",
              "      <td>38596</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>(2, 37624)</td>\n",
              "      <td>32649</td>\n",
              "      <td>5050</td>\n",
              "      <td>34405</td>\n",
              "      <td>48404</td>\n",
              "      <td>43756</td>\n",
              "      <td>19581</td>\n",
              "      <td>1985</td>\n",
              "      <td>36912</td>\n",
              "      <td>28457</td>\n",
              "      <td>...</td>\n",
              "      <td>39536</td>\n",
              "      <td>7744</td>\n",
              "      <td>13616</td>\n",
              "      <td>11921</td>\n",
              "      <td>1140</td>\n",
              "      <td>24986</td>\n",
              "      <td>8178</td>\n",
              "      <td>19577</td>\n",
              "      <td>37338</td>\n",
              "      <td>18657</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>(3, 33130)</td>\n",
              "      <td>7706</td>\n",
              "      <td>24412</td>\n",
              "      <td>18241</td>\n",
              "      <td>38745</td>\n",
              "      <td>43345</td>\n",
              "      <td>38608</td>\n",
              "      <td>43129</td>\n",
              "      <td>44668</td>\n",
              "      <td>2578</td>\n",
              "      <td>...</td>\n",
              "      <td>14984</td>\n",
              "      <td>36433</td>\n",
              "      <td>10382</td>\n",
              "      <td>13264</td>\n",
              "      <td>42512</td>\n",
              "      <td>37398</td>\n",
              "      <td>28594</td>\n",
              "      <td>16568</td>\n",
              "      <td>23680</td>\n",
              "      <td>1532</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>(4, 25257)</td>\n",
              "      <td>24924</td>\n",
              "      <td>9387</td>\n",
              "      <td>36992</td>\n",
              "      <td>5516</td>\n",
              "      <td>30135</td>\n",
              "      <td>10238</td>\n",
              "      <td>40738</td>\n",
              "      <td>44509</td>\n",
              "      <td>5677</td>\n",
              "      <td>...</td>\n",
              "      <td>4496</td>\n",
              "      <td>26082</td>\n",
              "      <td>2747</td>\n",
              "      <td>15780</td>\n",
              "      <td>23746</td>\n",
              "      <td>8108</td>\n",
              "      <td>31261</td>\n",
              "      <td>20875</td>\n",
              "      <td>368</td>\n",
              "      <td>47955</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 101 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dc116bb0-6952-4171-be25-9d61cddc35cd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dc116bb0-6952-4171-be25-9d61cddc35cd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dc116bb0-6952-4171-be25-9d61cddc35cd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_neg.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DjVA99Xg_WrY",
        "outputId": "db01ee97-2ddf-4908-fe0f-34ff55ffa02d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9997, 101)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install -y --no-install-recommends libnvinfer6=6.0.1-1+cuda10.1 \\\n",
        "    libnvinfer-dev=6.0.1-1+cuda10.1 \\\n",
        "    libnvinfer-plugin6=6.0.1-1+cuda10.1"
      ],
      "metadata": {
        "id": "x9_DcZ47BDQC",
        "outputId": "e594e547-ae38-4a45-ce91-946e53cfa039",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "E: Unable to locate package libnvinfer6\n",
            "E: Version '6.0.1-1+cuda10.1' for 'libnvinfer-dev' was not found\n",
            "E: Unable to locate package libnvinfer-plugin6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!export TF_CPP_MIN_LOG_LEVEL=\"2\""
      ],
      "metadata": {
        "id": "aES2HUtlK-QF"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UhkKaX2hmpqb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CJQ8fEhFmw5s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SfZ-rJ-am4aQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %pip install neural-tangents\n",
        "# !pip install -r /content/drive/MyDrive/infinite_ac_cf_main/requirements.txt\n",
        "# !pip install sciPy"
      ],
      "metadata": {
        "id": "gdY9YhzoaCkf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install neural-tangents"
      ],
      "metadata": {
        "id": "kMgKheJtRc-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install jax==0.3.0\n",
        "#!pip install jax jaxlib==0.3.0\n",
        "#!pip install jax tf2jax==0.3.0"
      ],
      "metadata": {
        "id": "j55F2Wlxad0p",
        "outputId": "3a5cd032-9e4d-4293-ac0f-67e5c6ea1ea9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting jax==0.3.0\n",
            "  Using cached jax-0.3.0-py3-none-any.whl\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.8/dist-packages (from jax==0.3.0) (3.3.0)\n",
            "Requirement already satisfied: scipy>=1.2.1 in /usr/local/lib/python3.8/dist-packages (from jax==0.3.0) (1.10.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.8/dist-packages (from jax==0.3.0) (1.4.0)\n",
            "Requirement already satisfied: numpy>=1.19 in /usr/local/lib/python3.8/dist-packages (from jax==0.3.0) (1.24.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from jax==0.3.0) (4.5.0)\n",
            "Installing collected packages: jax\n",
            "  Attempting uninstall: jax\n",
            "    Found existing installation: jax 0.4.4\n",
            "    Uninstalling jax-0.4.4:\n",
            "      Successfully uninstalled jax-0.4.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tf2jax 0.3.3 requires jax>=0.3.14, but you have jax 0.3.0 which is incompatible.\n",
            "neural-tangents 0.6.2 requires jax>=0.4.3, but you have jax 0.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed jax-0.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip list | grep jax"
      ],
      "metadata": {
        "id": "m3rarfosaKbh",
        "outputId": "8d6672bb-40b4-4755-ecb1-088b4bc7899a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "jax                           0.4.4\n",
            "jaxlib                        0.3.0\n",
            "tf2jax                        0.3.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/infinite_ac_cf_main"
      ],
      "metadata": {
        "id": "BfCuCxuVb-N-",
        "outputId": "2504e8ce-2900-413c-b6fe-a00af19f2e38",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/infinite_ac_cf_main\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pwd"
      ],
      "metadata": {
        "id": "4wHTJkq1b-wU",
        "outputId": "f75546f8-3cc7-4fcc-f9ce-74129b65474f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/infinite_ac_cf_main'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import neural_tangents"
      ],
      "metadata": {
        "id": "SwyrlPfyRiMx",
        "outputId": "91a08928-03aa-4eba-dba4-cc8c01eb3d69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-725f1322a39e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mneural_tangents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/neural_tangents/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0m__version__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'0.6.2'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mexperimental\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstax\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/neural_tangents/experimental/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# limitations under the License.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mempirical_tf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempirical\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mempirical_ntk_fn_tf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mempirical_tf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempirical\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_apply_fn_and_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/neural_tangents/experimental/empirical_tf/empirical.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjax2tf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mneural_tangents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_src\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempirical\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNtkImplementation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mempirical_ntk_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEFAULT_NTK_IMPLEMENTATION\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_DEFAULT_NTK_FWD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_DEFAULT_NTK_J_RULES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_DEFAULT_NTK_S_RULES\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mneural_tangents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_src\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPyTree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVMapAxes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/jax/experimental/jax2tf/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# flake8: noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m from jax.experimental.jax2tf.jax2tf import (convert, dtype_of_val,\n\u001b[0m\u001b[1;32m     17\u001b[0m                                             split_to_logical_devices, PolyShape)\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjax2tf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_tf\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcall_tf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/jax/experimental/jax2tf/jax2tf.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxla\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mxla_data_pb2\u001b[0m  \u001b[0;31m# type: ignore[import]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mattr_value_pb2\u001b[0m  \u001b[0;31m# type: ignore[import]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxla\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxla_sharding\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mxla_sharding\u001b[0m  \u001b[0;31m# type: ignore[import]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mops\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf_ops\u001b[0m  \u001b[0;31m# type: ignore[import]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;31m# pylint: enable=g-direct-tensorflow-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.compiler.xla.experimental'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import"
      ],
      "metadata": {
        "id": "qe-MAKsDgmGc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import jax\n",
        "import numpy as np\n",
        "import functools\n",
        "import h5py, sys, os\n",
        "import copy\n",
        "import h5py\n",
        "import gc\n",
        "import pickle\n",
        "import jax.numpy as jnp\n",
        "import time\n",
        "import random\n",
        "import heapq\n",
        "from sklearn.utils import shuffle\n",
        "from jax import scipy as sp\n",
        "from jax import numpy as jnp\n",
        "from neural_tangents import stax\n",
        "from collections import defaultdict\n",
        "from scipy.sparse import csr_matrix\n",
        "import os\n",
        "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"false\"\n",
        "os.environ[\"TF_FORCE_UNIFIED_MEMORY\"] = \"1\"\n",
        "os.environ[\"XLA_PYTHON_CLIENT_ALLOCATOR\"] = \"platform\""
      ],
      "metadata": {
        "id": "vJrjZyYngkrV",
        "outputId": "58f1eb73-6c61-4d13-949b-402cba4b4226",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-947235c6b166>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mjax\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mjax\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mneural_tangents\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstax\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcsr_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/neural_tangents/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0m__version__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'0.6.2'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mexperimental\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstax\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/neural_tangents/experimental/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# limitations under the License.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mempirical_tf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempirical\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mempirical_ntk_fn_tf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mempirical_tf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempirical\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_apply_fn_and_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/neural_tangents/experimental/empirical_tf/empirical.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjax2tf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mneural_tangents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_src\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempirical\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNtkImplementation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mempirical_ntk_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEFAULT_NTK_IMPLEMENTATION\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_DEFAULT_NTK_FWD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_DEFAULT_NTK_J_RULES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_DEFAULT_NTK_S_RULES\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mneural_tangents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_src\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPyTree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVMapAxes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/jax/experimental/jax2tf/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# limitations under the License.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m from jax.experimental.jax2tf.jax2tf import (convert, dtype_of_val,\n\u001b[0m\u001b[1;32m     16\u001b[0m                                             split_to_logical_devices, PolyShape)\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjax2tf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_tf\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcall_tf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/jax/experimental/jax2tf/jax2tf.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_src\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_src\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapi_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_src\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_src\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_src\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/jax/_src/core.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_src\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msource_info_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m from jax._src.util import (safe_zip, safe_map, curry, prod, tuple_insert,\n\u001b[0m\u001b[1;32m     47\u001b[0m                            \u001b[0mtuple_delete\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_hashable_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m                            HashableFunction, HashableWrapper, weakref_lru_cache)\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'HashableWrapper' from 'jax._src.util' (/usr/local/lib/python3.8/dist-packages/jax/_src/util.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Model"
      ],
      "metadata": {
        "id": "zfv189FjQFIK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utils"
      ],
      "metadata": {
        "id": "LwuPpMDucbAC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_common_path(hyper_params):\n",
        "    ret = \"{}_users_{}_depth_{}_\".format(\n",
        "        hyper_params['dataset'], hyper_params['user_support'],\n",
        "        hyper_params['depth']\n",
        "    )\n",
        "    \n",
        "    if hyper_params['grid_search_lamda']: ret += \"grid_search_lamda_\"\n",
        "    else: ret += \"lamda_{}_\".format(hyper_params['lamda'])\n",
        "    \n",
        "    ret += \"seed_{}\".format(hyper_params['seed'])\n",
        "    return ret\n",
        "\n",
        "def get_item_count_map(data):\n",
        "    item_count = defaultdict(int)\n",
        "    for u, i, r in data.data['train']: item_count[i] += 1\n",
        "    return item_count\n",
        "\n",
        "def get_item_propensity(hyper_params, data, A = 0.55, B = 1.5):\n",
        "    item_freq_map = get_item_count_map(data)\n",
        "    item_freq = [ item_freq_map[i] for i in range(hyper_params['num_items']) ]\n",
        "    num_instances = hyper_params['num_interactions']\n",
        "\n",
        "    C = (np.log(num_instances)-1)*np.power(B+1, A)\n",
        "    wts = 1.0 + C*np.power(np.array(item_freq)+B, -A)\n",
        "    return np.ravel(wts)\n",
        "\n",
        "def file_write(log_file, s, dont_print=False):\n",
        "    if dont_print == False: print(s)\n",
        "    if log_file is None: return\n",
        "    f = open(log_file, 'a')\n",
        "    f.write(s+'\\n')\n",
        "    f.close()\n",
        "\n",
        "def log_end_epoch(hyper_params, metrics, step, time_elpased, metrics_on = '(TEST)', dont_print = False):\n",
        "    string2 = \"\"\n",
        "    for m in metrics: string2 += \" | \" + m + ' = ' + str(\"{:2.4f}\".format(metrics[m]))\n",
        "    string2 += ' ' + metrics_on\n",
        "\n",
        "    ss  = '| end of step {:4d} | time = {:5.2f}'.format(step, time_elpased)\n",
        "    ss += string2\n",
        "    file_write(hyper_params['log_file'], ss, dont_print = dont_print)"
      ],
      "metadata": {
        "id": "q1DaMnZAcaMt"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data"
      ],
      "metadata": {
        "id": "QSVndSQXbO-l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('test.pickle', 'rb') as f:\n",
        "   test_pickle = pickle.load(f)\n",
        "\n",
        "class Dataset:\n",
        "    def __init__(self, hyper_params):\n",
        "        self.data = load_raw_dataset(hyper_params['dataset'])\n",
        "        self.set_of_active_users = list(set(self.data['train'][:, 0].tolist()))            \n",
        "        self.hyper_params = self.update_hyper_params(hyper_params)\n",
        "\n",
        "    def update_hyper_params(self, hyper_params):\n",
        "        updated_params = copy.deepcopy(hyper_params)\n",
        "        \n",
        "        self.num_users, self.num_items = self.data['num_users'], self.data['num_items']\n",
        "        self.num_interactions = self.data['num_interactions']\n",
        "\n",
        "        # Update hyper-params to have some basic data stats\n",
        "        updated_params.update({\n",
        "            'num_users': self.num_users,\n",
        "            'num_items': self.num_items,\n",
        "            'num_interactions': self.num_interactions\n",
        "        })\n",
        "\n",
        "        return updated_params\n",
        "\n",
        "    def sample_users(self, num_to_sample):\n",
        "        if num_to_sample == -1: \n",
        "            ret = self.data['train_matrix']\n",
        "        else: \n",
        "            sampled_users = np.random.choice(self.set_of_active_users, num_to_sample, replace=False)\n",
        "            sampled_interactions = self.data['train'][np.in1d(self.data['train'][:, 0], sampled_users)]\n",
        "            ret = csr_matrix(\n",
        "                ( np.ones(sampled_interactions.shape[0]), (sampled_interactions[:, 0], sampled_interactions[:, 1]) ),\n",
        "                shape = (self.num_users, self.num_items)\n",
        "            )\n",
        "\n",
        "        # This just removes the users which were not sampled\n",
        "        return jnp.array(ret[ret.getnnz(1)>0].todense())\n",
        "\n",
        "def load_raw_dataset(dataset, data_path = None, index_path = None):\n",
        "    if data_path is None or index_path is None:\n",
        "        data_path, index_path = [\n",
        "            \"/content/drive/MyDrive/ml-1m{}/total_data.hdf5\".format(dataset),\n",
        "            \"/content/drive/MyDrive/ml-1m{}/index.npz\".format(dataset)\n",
        "        ]\n",
        "\n",
        "    with h5py.File(data_path, 'r') as f: data = np.array(list(zip(f['user'][:], f['item'][:], f['rating'][:])))\n",
        "    index = np.array(np.load(index_path)['data'], dtype = np.int32)\n",
        "\n",
        "    def remap(data, index):\n",
        "        ## Counting number of unique users/items before\n",
        "        valid_users, valid_items = set(), set()\n",
        "        for at, (u, i, r) in enumerate(data):\n",
        "            if index[at] != -1:\n",
        "                valid_users.add(u)\n",
        "                valid_items.add(i)\n",
        "\n",
        "        ## Map creation done!\n",
        "        user_map = dict(zip(list(valid_users), list(range(len(valid_users)))))\n",
        "        item_map = dict(zip(list(valid_items), list(range(len(valid_items)))))\n",
        "\n",
        "        return user_map, item_map\n",
        "\n",
        "    user_map, item_map = remap(data, index)\n",
        "\n",
        "    new_data, new_index = [], []\n",
        "    for at, (u, i, r) in enumerate(data):\n",
        "        if index[at] == -1: continue\n",
        "        new_data.append([ user_map[u], item_map[i], r ])\n",
        "        new_index.append(index[at])\n",
        "    data = np.array(new_data, dtype = np.int32)\n",
        "    index = np.array(new_index, dtype = np.int32)\n",
        "\n",
        "    def select(data, index, index_val):\n",
        "        final = data[np.where(index == index_val)[0]]\n",
        "        final[:, 2] = 1.0\n",
        "        return final.astype(np.int32)\n",
        "\n",
        "    ret = {\n",
        "        'item_map': item_map,\n",
        "        'train':  select(data, index, 0),\n",
        "        'val': select(data, index, 1),\n",
        "        #'test': test_pickle\n",
        "        'test': select(data, index, 2)\n",
        "    }\n",
        "    #print(ret['test'])\n",
        "\n",
        "    num_users = int(max(data[:, 0]) + 1)\n",
        "    num_items = len(item_map)\n",
        "    print(num_users, num_items)\n",
        "\n",
        "    del data, index ; gc.collect()\n",
        "\n",
        "    def make_user_history(arr):\n",
        "        ret = [ set() for _ in range(num_users) ] #[ set() for _ in range(num_users) ]\n",
        "        for u, i, r in arr:\n",
        "            if i >= num_items: continue\n",
        "            ret[int(u)].add(int(i))\n",
        "        return ret\n",
        "\n",
        "    ret['train_positive_set'] = make_user_history(ret['train'])\n",
        "    ret['val_positive_set'] = make_user_history(ret['val'])\n",
        "    ret['test_positive_set'] = make_user_history(ret['test'])\n",
        "\n",
        "    ret['train_matrix'] = csr_matrix(\n",
        "        ( np.ones(ret['train'].shape[0]), (ret['train'][:, 0].astype(np.int32), ret['train'][:, 1].astype(np.int32)) ),\n",
        "        shape = (num_users, num_items)\n",
        "    )\n",
        "\n",
        "    ret['val_matrix'] = csr_matrix(\n",
        "        ( np.ones(ret['val'].shape[0]), (ret['val'][:, 0].astype(np.int32), ret['val'][:, 1].astype(np.int32)) ),\n",
        "        shape = (num_users, num_items)\n",
        "    )\n",
        "\n",
        "    # Negatives will be used for AUC computation\n",
        "    ret['negatives'] = [ set() for _ in range(num_users) ]\n",
        "    for u in range(num_users):\n",
        "        while len(ret['negatives'][u]) < 50:\n",
        "            rand_item = np.random.randint(0, num_items)\n",
        "            if rand_item in ret['train_positive_set'][u]: continue\n",
        "            if rand_item in ret['test_positive_set'][u]: continue\n",
        "            ret['negatives'][u].add(rand_item)\n",
        "        ret['negatives'][u] = list(ret['negatives'][u])\n",
        "    ret['negatives'] = np.array(ret['negatives'], dtype=np.int32)\n",
        "\n",
        "    ret.update({\n",
        "        'num_users': num_users,\n",
        "        'num_items': num_items,\n",
        "        'num_interactions': len(ret['train']),\n",
        "    })\n",
        "    print(\"# users:\", num_users)\n",
        "    print(\"# items:\", num_items)\n",
        "    print(\"# interactions:\", len(ret['train']))\n",
        "\n",
        "    return ret"
      ],
      "metadata": {
        "id": "FcVxg3SjbOeI"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocess"
      ],
      "metadata": {
        "id": "NV2GAXtucsJV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BASE_PATH = '/content/drive/MyDrive/ml-1m'\n",
        "#base_path\n",
        "\n",
        "def prep_movielens(ratings_file_path):\n",
        "    f = open(ratings_file_path, \"r\")\n",
        "    users, items, ratings = [], [], []\n",
        "\n",
        "    line = f.readline()\n",
        "    while line:\n",
        "        u, i, r,_ = line.strip().split(\"::\")\n",
        "        users.append(int(u))\n",
        "        items.append(int(i))\n",
        "        ratings.append(float(r))\n",
        "        line = f.readline()\n",
        "\n",
        "    min_user = min(users)\n",
        "    num_users = len(set(users))\n",
        "\n",
        "    data = [ [] for _ in range(num_users) ]\n",
        "    for i in range(len(users)):\n",
        "        data[users[i] - min_user].append([ items[i], ratings[i] ])\n",
        "\n",
        "    return rating_data(data)\n",
        "\n",
        "class rating_data:\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "\n",
        "        self.index = [] # 0: train, 1: validation, 2: test, -1: removed due to user frequency < 3\n",
        "        for user_data in self.data:\n",
        "            for _ in range(len(user_data)): self.index.append(42)\n",
        "\n",
        "    def train_test_split(self):\n",
        "        at = 0\n",
        "\n",
        "        for user in range(len(self.data)):\n",
        "            first_split_point = int(0.8 * len(self.data[user]))\n",
        "            second_split_point = int(0.9 * len(self.data[user]))\n",
        "\n",
        "            indices = np.arange(len(self.data[user]))\n",
        "            np.random.shuffle(indices)\n",
        "\n",
        "            for timestep, (item, rating) in enumerate(self.data[user]):\n",
        "                if len(self.data[user]) < 3: self.index[at] = -1\n",
        "                else:\n",
        "                    # Force atleast one element in user history to be in test\n",
        "                    if timestep == indices[0]: self.index[at] = 2\n",
        "                    else:\n",
        "                        if timestep in indices[:first_split_point]: self.index[at] = 0\n",
        "                        elif timestep in indices[first_split_point:second_split_point]: self.index[at] = 1\n",
        "                        else: self.index[at] = 2\n",
        "                at += 1\n",
        "\n",
        "        assert at == len(self.index)\n",
        "        self.complete_data_stats = None\n",
        "\n",
        "    def save_index(self, path):\n",
        "        os.makedirs(path, exist_ok = True)\n",
        "        with open(path + \"/index.npz\", \"wb\") as f: np.savez_compressed(f, data = self.index)\n",
        "\n",
        "    def save_data(self, path):\n",
        "        flat_data = []\n",
        "        for u in range(len(self.data)):\n",
        "            flat_data += list(map(lambda x: [ u ] + x, self.data[u]))\n",
        "        flat_data = np.array(flat_data)\n",
        "\n",
        "        shape = [ len(flat_data) ]\n",
        "\n",
        "        os.makedirs(path, exist_ok = True)\n",
        "        with h5py.File(path + '/total_data.hdf5', 'w') as file:\n",
        "            dset = {}\n",
        "            dset['user'] = file.create_dataset(\"user\", shape, dtype = 'i4', maxshape = shape, compression=\"gzip\")\n",
        "            dset['item'] = file.create_dataset(\"item\", shape, dtype = 'i4', maxshape = shape, compression=\"gzip\")\n",
        "            dset['rating'] = file.create_dataset(\"rating\", shape, dtype = 'f', maxshape = shape, compression=\"gzip\")\n",
        "\n",
        "            dset['user'][:] = flat_data[:, 0]\n",
        "            dset['item'][:] = flat_data[:, 1]\n",
        "            dset['rating'][:] = flat_data[:, 2]\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    if len(sys.argv) < 2: \n",
        "        print(\"This file needs the dataset name as the first argument...\")\n",
        "        exit(0)\n",
        "    \n",
        "    dataset = sys.argv[1]\n",
        "\n",
        "    print(\"\\n\\n!!!!!!!! STARTED PROCESSING {} !!!!!!!!\".format(dataset))\n",
        "\n",
        "    #if dataset in [ 'ml-1m' ]: total_data = prep_movielens(BASE_PATH +\"/ratings.dat\") #\"/ratings.dat\"\n",
        "    total_data = prep_movielens(BASE_PATH +\"/ratings.dat\")\n",
        "\n",
        "    total_data.save_data(BASE_PATH + \"{}/\".format(dataset))\n",
        "    total_data.train_test_split()\n",
        "    total_data.save_index(BASE_PATH + \"{}/\".format(dataset))"
      ],
      "metadata": {
        "id": "eTeAAUEQcqzq",
        "outputId": "aa781a7f-3a19-42f9-a292-4af218ef3f8c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "!!!!!!!! STARTED PROCESSING -f !!!!!!!!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyper_params"
      ],
      "metadata": {
        "id": "0JNE6skYcLGE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hyper_params = {\n",
        "\t'dataset': 'ml-1m', \n",
        "\t'float64': False,\n",
        "\n",
        "\t'depth': 1,\n",
        "\t'grid_search_lamda': True,\n",
        "\t'lamda': 1, # Only used if grid_search_lamda == False\n",
        "\n",
        "\t# Number of users to keep (randomly)\n",
        "\t'user_support': -1, # -1 implies use all users\n",
        "\t'seed': 42,\n",
        "}\n"
      ],
      "metadata": {
        "id": "9kIzDX8FcI_w"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model"
      ],
      "metadata": {
        "id": "dOFlQqjof9r0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_kernelized_rr_forward(hyper_params):\n",
        "    _, _, kernel_fn = FullyConnectedNetwork(\n",
        "        depth=hyper_params['depth'],\n",
        "        num_classes=hyper_params['num_items']\n",
        "    )\n",
        "    # NOTE: Un-comment this if the dataset size is very big (didn't need it for experiments in the paper)\n",
        "    # kernel_fn = nt.batch(kernel_fn, batch_size=128)\n",
        "    kernel_fn = functools.partial(kernel_fn, get='ntk')\n",
        "\n",
        "    @jax.jit\n",
        "    def kernelized_rr_forward(X_train, X_predict, reg=0.1):\n",
        "        K_train = kernel_fn(X_train, X_train)\n",
        "        K_predict = kernel_fn(X_predict, X_train)\n",
        "        K_reg = (K_train + jnp.abs(reg) * jnp.trace(K_train) * jnp.eye(K_train.shape[0]) / K_train.shape[0])     \n",
        "        return jnp.dot(K_predict, sp.linalg.solve(K_reg, X_train, sym_pos=True))\n",
        "\n",
        "    return kernelized_rr_forward, kernel_fn\n",
        "\n",
        "def FullyConnectedNetwork( \n",
        "    depth,\n",
        "    W_std = 2 ** 0.5, \n",
        "    b_std = 0.1,\n",
        "    num_classes = 10,\n",
        "    parameterization = 'ntk'\n",
        "):\n",
        "    activation_fn = stax.Relu()\n",
        "    dense = functools.partial(stax.Dense, W_std=W_std, b_std=b_std, parameterization=parameterization)\n",
        "\n",
        "    layers = [stax.Flatten()]\n",
        "    # NOTE: setting width = 1024 doesn't matter as the NTK parameterization will stretch this till \\infty\n",
        "    for _ in range(depth): layers += [dense(1024), activation_fn] \n",
        "    layers += [stax.Dense(num_classes, W_std=W_std, b_std=b_std, parameterization=parameterization)]\n",
        "\n",
        "    return stax.serial(*layers)\n"
      ],
      "metadata": {
        "id": "klyQisKI_63l"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate"
      ],
      "metadata": {
        "id": "WzIz4KhLbvzM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import jax\n",
        "#import numpy as np\n",
        "#import jax.numpy as jnp\n",
        "#from numba import jit, float64\n",
        "\n",
        "INF = float(1e6)\n",
        "\n",
        "def evaluate(hyper_params, kernelized_rr_forward, data, item_propensity, train_x, topk = [ 10, 100 ], test_set_eval = False):\n",
        "    preds, y_binary, metrics = [], [], {}\n",
        "    for kind in [ 'HR', 'NDCG', 'PSP' ]:\n",
        "        for k in topk: \n",
        "            metrics['{}@{}'.format(kind, k)] = 0.0\n",
        "\n",
        "    # Train positive set -- these items will be set to -infinity while prediction on the val/test set\n",
        "    train_positive_list = list(map(list, data.data['train_positive_set']))\n",
        "    if test_set_eval:\n",
        "        for u in range(len(train_positive_list)): train_positive_list[u] += list(data.data['val_positive_set'][u])\n",
        "\n",
        "    # Train positive interactions (in matrix form) as context for prediction on val/test set\n",
        "    eval_context = data.data['train_matrix']\n",
        "    if test_set_eval: eval_context += data.data['val_matrix']\n",
        "\n",
        "    # What needs to be predicted\n",
        "    to_predict = data.data['val_positive_set']\n",
        "    if test_set_eval: to_predict = data.data['test_positive_set']\n",
        "\n",
        "    bsz = 20_000 # These many users\n",
        "    for i in range(0, hyper_params['num_users'], bsz):\n",
        "        temp_preds = kernelized_rr_forward(train_x, eval_context[i:i+bsz].todense(), reg = hyper_params['lamda'])\n",
        "        #np.save('/content/drive/MyDrive/infinite_ac_cf_main/kernel', temp_preds) # dual parameter save\n",
        "        metrics, temp_preds, temp_y = evaluate_batch(\n",
        "            data.data['negatives'][i:i+bsz], np.array(temp_preds), \n",
        "            train_positive_list[i:i+bsz], to_predict[i:i+bsz], item_propensity, \n",
        "            topk, metrics\n",
        "        )\n",
        "        \n",
        "        preds += temp_preds\n",
        "        y_binary += temp_y\n",
        "\n",
        "    y_binary, preds = np.array(y_binary), np.array(preds)\n",
        "    if (True not in np.isnan(y_binary)) and (True not in np.isnan(preds)):\n",
        "        metrics['AUC'] = round(fast_auc(y_binary, preds), 4)\n",
        "\n",
        "    for kind in [ 'HR', 'NDCG', 'PSP' ]:\n",
        "        for k in topk: \n",
        "            metrics['{}@{}'.format(kind, k)] = round(\n",
        "                float(100.0 * metrics['{}@{}'.format(kind, k)]) / hyper_params['num_users'], 4\n",
        "            )\n",
        "\n",
        "    metrics['num_users'] = int(train_x.shape[0])\n",
        "    metrics['num_interactions'] = int(jnp.count_nonzero(train_x.astype(np.int8)))\n",
        "\n",
        "    return metrics\n",
        "\n",
        "def evaluate_batch(auc_negatives, logits, train_positive, test_positive_set, item_propensity, topk, metrics, train_metrics = False):\n",
        "    # AUC Stuff\n",
        "    temp_preds, temp_y = [], []\n",
        "    for b in range(len(logits)):\n",
        "        temp_preds += np.take(logits[b], np.array(list(test_positive_set[b]))).tolist()\n",
        "        temp_y += [ 1.0 for _ in range(len(test_positive_set[b])) ]\n",
        "\n",
        "        temp_preds += np.take(logits[b], auc_negatives[b]).tolist()\n",
        "        temp_y += [ 0.0 for _ in range(len(auc_negatives[b])) ]\n",
        "    # Marking train-set consumed items as negative INF\n",
        "    for b in range(len(logits)): logits[b][ train_positive[b] ] = -INF\n",
        "\n",
        "    indices = (-logits).argsort()[:, :max(topk)].tolist()\n",
        "\n",
        "    for k in topk: \n",
        "        for b in range(len(logits)):\n",
        "            num_pos = float(len(test_positive_set[b]))\n",
        "\n",
        "            metrics['HR@{}'.format(k)] += float(len(set(indices[b][:k]) & test_positive_set[b])) / float(min(num_pos, k))\n",
        "\n",
        "            test_positive_sorted_psp = sorted([ item_propensity[x] for x in test_positive_set[b] ])[::-1]\n",
        "\n",
        "            dcg, idcg, psp, max_psp = 0.0, 0.0, 0.0, 0.0\n",
        "            for at, pred in enumerate(indices[b][:k]):\n",
        "                if pred in test_positive_set[b]: \n",
        "                    dcg += 1.0 / np.log2(at + 2)\n",
        "                    psp += float(item_propensity[pred]) / float(min(num_pos, k))\n",
        "                if at < num_pos: \n",
        "                    idcg += 1.0 / np.log2(at + 2)\n",
        "                    max_psp += test_positive_sorted_psp[at]\n",
        "\n",
        "            metrics['NDCG@{}'.format(k)] += dcg / idcg\n",
        "            metrics['PSP@{}'.format(k)] += psp / max_psp\n",
        "\n",
        "    return metrics, temp_preds, temp_y\n",
        "\n",
        "#@jit(float64(float64[:], float64[:]))\n",
        "def fast_auc(y_true, y_prob):\n",
        "    y_true = y_true[np.argsort(y_prob)]\n",
        "    nfalse, auc = 0, 0\n",
        "    for i in range(len(y_true)):\n",
        "        nfalse += (1 - y_true[i])\n",
        "        auc += y_true[i] * nfalse\n",
        "    return auc / (nfalse * (len(y_true) - nfalse))"
      ],
      "metadata": {
        "id": "W-5lEraFaQMg"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Main model"
      ],
      "metadata": {
        "id": "M7x7GT6wdZ2L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(hyper_params, data):\n",
        "\n",
        "    # This just instantiates the function\n",
        "    kernelized_rr_forward, kernel_fn = make_kernelized_rr_forward(hyper_params)\n",
        "    #np.save('/content/drive/MyDrive/infinite_ac_cf_main/kernelized_rr_forward', kernelized_rr_forward) # x_save.npy\n",
        "    sampled_matrix = data.sample_users(hyper_params['user_support']) # Random user sample\n",
        "\n",
        "    '''\n",
        "    NOTE: No training required! We will compute dual-variables \\alpha on the fly in `kernelized_rr_forward`\n",
        "          However, if we needed to perform evaluation multiple times, we could pre-compute \\alpha like so:\n",
        "    \n",
        "    import jax, jax.numpy as jnp, jax.scipy as sp\n",
        "    @jax.jit\n",
        "    def precompute_alpha(X, lamda=0.1):\n",
        "        K = kernel_fn(X, X)\n",
        "        K_reg = (K + jnp.abs(lamda) * jnp.trace(K) * jnp.eye(K.shape[0]) / K.shape[0])\n",
        "        return sp.linalg.solve(K_reg, X, sym_pos=True)\n",
        "    alpha = precompute_alpha(sampled_matrix, lamda=0.1) # Change for the desired value of lamda\n",
        "    '''\n",
        "\n",
        "    # Used for computing the PSP-metric\n",
        "    item_propensity = get_item_propensity(hyper_params, data)\n",
        "    \n",
        "    # Evaluation\n",
        "    start_time = time.time()\n",
        "\n",
        "    VAL_METRIC = \"HR@100\"\n",
        "    best_metric, best_lamda = None, None\n",
        "\n",
        "    # Validate on the validation-set\n",
        "    for lamda in [ 0.0, 1.0, 5.0, 20.0, 50.0, 100.0 ] if hyper_params['grid_search_lamda'] else [ hyper_params['lamda'] ]:\n",
        "        hyper_params['lamda'] = lamda\n",
        "        val_metrics = evaluate(hyper_params, kernelized_rr_forward, data, item_propensity, sampled_matrix)\n",
        "        if (best_metric is None) or (val_metrics[VAL_METRIC] > best_metric): best_metric, best_lamda = val_metrics[VAL_METRIC], lamda\n",
        "\n",
        "    # Return metrics with the best lamda on the test-set\n",
        "    hyper_params['lamda'] = best_lamda\n",
        "    test_metrics = evaluate(hyper_params, kernelized_rr_forward, data, item_propensity, sampled_matrix, test_set_eval = True)\n",
        "    \n",
        "    log_end_epoch(hyper_params, test_metrics, 0, time.time() - start_time)\n",
        "    start_time = time.time()\n",
        "\n",
        "    return test_metrics, val_metrics\n",
        "\n",
        "def main(hyper_params, gpu_id = None):\n",
        "    if gpu_id is not None: os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(gpu_id)\n",
        "    if 'float64' in hyper_params and hyper_params['float64'] == True: config.update('jax_enable_x64', True)\n",
        "\n",
        "    np.random.seed(hyper_params['seed'])\n",
        "    random.seed(hyper_params['seed'])\n",
        "\n",
        "    os.makedirs(\"./results/logs/\", exist_ok=True)\n",
        "    hyper_params['log_file'] = \"./results/logs/\" + get_common_path(hyper_params) + \".txt\"\n",
        "    \n",
        "    data = Dataset(hyper_params)\n",
        "    hyper_params = copy.deepcopy(data.hyper_params) # Updated w/ data-stats\n",
        "\n",
        "    return train(hyper_params, data)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    test, val = main(hyper_params)"
      ],
      "metadata": {
        "id": "IxJaizJQbnhL",
        "outputId": "5219b2d3-1ea2-42b0-f2d0-024ca6ca873e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6040 3706\n",
            "# users: 6040\n",
            "# items: 3706\n",
            "# interactions: 791718\n",
            "| end of step    0 | time = 209.60 | HR@10 = 31.8885 | HR@100 = 60.5264 | NDCG@10 = 33.2327 | NDCG@100 = 42.9653 | PSP@10 = 3.2817 | PSP@100 = 6.6276 | AUC = 0.9456 | num_users = 6040.0000 | num_interactions = 791718.0000 (TEST)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(test)"
      ],
      "metadata": {
        "id": "5z14jc2mtv3X",
        "outputId": "81a5ba2f-ed73-45c9-8d20-791155981591",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'HR@10': 31.8885,\n",
              " 'HR@100': 60.5264,\n",
              " 'NDCG@10': 33.2327,\n",
              " 'NDCG@100': 42.9653,\n",
              " 'PSP@10': 3.2817,\n",
              " 'PSP@100': 6.6276,\n",
              " 'AUC': 0.9456,\n",
              " 'num_users': 6040,\n",
              " 'num_interactions': 791718}"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(val)"
      ],
      "metadata": {
        "id": "ifktE3ppumMh",
        "outputId": "29468aa0-1ebe-43cd-f036-316e7b340bc0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'HR@10': 16.1385,\n",
              " 'HR@100': 42.0721,\n",
              " 'NDCG@10': 16.4508,\n",
              " 'NDCG@100': 25.1162,\n",
              " 'PSP@10': 1.8948,\n",
              " 'PSP@100': 6.1856,\n",
              " 'AUC': 0.9305,\n",
              " 'num_users': 6040,\n",
              " 'num_interactions': 791718}"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = Dataset(hyper_params)"
      ],
      "metadata": {
        "id": "GSD9a_Bfibua",
        "outputId": "61068b7b-3bd4-46d6-e0f6-b7339bb57842",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6040 3706\n",
            "# users: 6040\n",
            "# items: 3706\n",
            "# interactions: 791718\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.data['train_matrix'].size"
      ],
      "metadata": {
        "id": "U9Mh-dKbib_T",
        "outputId": "a8ab4b58-17c0-4189-f811-589451761865",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "791718"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "qJWCGeMgkWY6"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(data.data)"
      ],
      "metadata": {
        "id": "Kwqq5txyi-ue",
        "outputId": "87379b6b-1b88-4e20-98bf-20a514ca3b7b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['item_map',\n",
              " 'train',\n",
              " 'val',\n",
              " 'test',\n",
              " 'train_positive_set',\n",
              " 'val_positive_set',\n",
              " 'test_positive_set',\n",
              " 'train_matrix',\n",
              " 'val_matrix',\n",
              " 'negatives',\n",
              " 'num_users',\n",
              " 'num_items',\n",
              " 'num_interactions']"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Neural MF"
      ],
      "metadata": {
        "id": "9hWefEZywNRw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data loder"
      ],
      "metadata": {
        "id": "R0m-6nnwwSAU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Loader():\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def load_dataset(self):\n",
        "        \"\"\"\n",
        "        데이터 로드 함수\n",
        "\n",
        "        uids: train user\n",
        "        iids: train item\n",
        "        users: 전체 user\n",
        "        items: 전체 item\n",
        "        df_train\n",
        "        df_test\n",
        "        \"\"\"\n",
        "        # 데이터 로드\n",
        "        file_path = '/content/drive/MyDrive/Neural_CF-master/lastfm-dataset-360K'\n",
        "        df = pd.read_csv(file_path + '/usersha1-artmbid-artname-plays.tsv', delimiter='\\t', header=None)\n",
        "        df = df.drop(df.columns[2], axis=1)\n",
        "        df.columns = ['user', 'item', 'plays']\n",
        "        df = df.dropna()\n",
        "        df = df.loc[df.plays != 0]\n",
        "\n",
        "        # user 샘플링\n",
        "        sample_num = 100000\n",
        "        unique_user_lst = list(np.unique(df['user']))  # 358857명\n",
        "        sample_user_idx = np.random.choice(len(unique_user_lst), sample_num, replace=False)\n",
        "        sample_user_lst = [unique_user_lst[idx] for idx in sample_user_idx]\n",
        "        df = df[df['user'].isin(sample_user_lst)]\n",
        "        df = df.reset_index(drop=True)\n",
        "\n",
        "        # 1명 이상의 artist 데이터가 있는 user 만 사용\n",
        "        df_count = df.groupby(['user']).count()\n",
        "        df['count'] = df.groupby('user')['user'].transform('count')\n",
        "        df = df[df['count'] > 1]\n",
        "\n",
        "        # user, item 아이디 부여\n",
        "        df['user_id'] = df['user'].astype(\"category\").cat.codes\n",
        "        df['item_id'] = df['item'].astype(\"category\").cat.codes\n",
        "\n",
        "        # lookup 테이블 생성\n",
        "        item_lookup = df[['item_id', 'item']].drop_duplicates()\n",
        "        item_lookup['item_id'] = item_lookup.item_id.astype(str)\n",
        "\n",
        "        # train, test 데이터 생성\n",
        "        df = df[['user_id', 'item_id', 'plays']]\n",
        "        df_train, df_test = self.train_test_split(df)\n",
        "\n",
        "        # 전체 user, item 리스트 생성\n",
        "        users = list(np.sort(df.user_id.unique()))\n",
        "        items = list(np.sort(df.item_id.unique()))\n",
        "\n",
        "        # train user, item 리스트 생성\n",
        "        rows = df_train['user_id'].astype(int)\n",
        "        cols = df_train['item_id'].astype(int)\n",
        "        values = list(df_train.plays)\n",
        "\n",
        "        uids = np.array(rows.tolist())\n",
        "        iids = np.array(cols.tolist())\n",
        "\n",
        "        # 각 user 마다 negative item 생성\n",
        "        df_neg = self.get_negatives(uids, iids, items, df_test)\n",
        "\n",
        "        return uids, iids, df_train, df_test, df_neg, users, items, item_lookup\n",
        "\n",
        "    def get_negatives(self, uids, iids, items, df_test):\n",
        "        \"\"\"\n",
        "        negative item 리스트 생성함수\n",
        "        \"\"\"\n",
        "        negativeList = []\n",
        "        test_u = df_test['user_id'].values.tolist()\n",
        "        test_i = df_test['item_id'].values.tolist()\n",
        "\n",
        "        test_ratings = list(zip(test_u, test_i))  # test (user, item)세트\n",
        "        zipped = set(zip(uids, iids))             # train (user, item)세트\n",
        "\n",
        "        for (u, i) in test_ratings:\n",
        "\n",
        "            negatives = []\n",
        "            negatives.append((u, i))\n",
        "            for t in range(100):\n",
        "                j = np.random.randint(len(items))     # neg_item j 1개 샘플링\n",
        "                while (u, j) in zipped:               # j가 train에 있으면 다시뽑고, 없으면 선택\n",
        "                    j = np.random.randint(len(items))\n",
        "                negatives.append(j)\n",
        "            negativeList.append(negatives) # [(0,pos), neg, neg, ...]\n",
        "\n",
        "        df_neg = pd.DataFrame(negativeList)\n",
        "\n",
        "        return df_neg\n",
        "\n",
        "    def mask_first(self, x):\n",
        "\n",
        "        result = np.ones_like(x)\n",
        "        result[0] = 0  # [0,1,1,....]\n",
        "\n",
        "        return result\n",
        "\n",
        "    def train_test_split(self, df):\n",
        "        \"\"\"\n",
        "        train, test 나누는 함수\n",
        "        \"\"\"\n",
        "        df_test = df.copy(deep=True)\n",
        "        df_train = df.copy(deep=True)\n",
        "\n",
        "        # df_test\n",
        "        # user_id와 holdout_item_id(user가 플레이한 아이템 중 1개)뽑기\n",
        "        df_test = df_test.groupby(['user_id']).first()\n",
        "        df_test['user_id'] = df_test.index\n",
        "        df_test = df_test[['user_id', 'item_id', 'plays']]\n",
        "        df_test = df_test.reset_index(drop=True)\n",
        "\n",
        "        # df_train\n",
        "        # user_id 리스트에 make_first()적용\n",
        "        mask = df.groupby(['user_id'])['user_id'].transform(self.mask_first).astype(bool)\n",
        "        df_train = df.loc[mask]\n",
        "\n",
        "        return df_train, df_test\n",
        "\n",
        "    def get_train_instances(self, uids, iids, num_neg, num_items):\n",
        "        \"\"\"\n",
        "        모델에 사용할 train 데이터 생성 함수\n",
        "        \"\"\"\n",
        "        user_input, item_input, labels = [],[],[]\n",
        "        zipped = set(zip(uids, iids)) # train (user, item) 세트\n",
        "\n",
        "        for (u, i) in zip(uids, iids):\n",
        "\n",
        "            # pos item 추가\n",
        "            user_input.append(u)  # [u]\n",
        "            item_input.append(i)  # [pos_i]\n",
        "            labels.append(1)      # [1]\n",
        "\n",
        "            # neg item 추가\n",
        "            for t in range(num_neg):\n",
        "\n",
        "                j = np.random.randint(num_items)      # neg_item j num_neg 개 샘플링\n",
        "                while (u, j) in zipped:               # u가 j를 이미 선택했다면\n",
        "                    j = np.random.randint(num_items)  # 다시 샘플링\n",
        "\n",
        "                user_input.append(u)  # [u1, u1,  u1,  ...]\n",
        "                item_input.append(j)  # [pos_i, neg_j1, neg_j2, ...]\n",
        "                labels.append(0)      # [1, 0,  0,  ...]\n",
        "\n",
        "        return user_input, item_input, labels"
      ],
      "metadata": {
        "id": "kFQ0VDGdkeEx"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Metric"
      ],
      "metadata": {
        "id": "c5I7vOdiweAl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Metric:\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def get_hits(self, k_ranked, holdout):\n",
        "        \"\"\"\n",
        "        hit 생성 함수\n",
        "        hit := holdout(df_test의 item)이 K순위 내에 있는지 여부\n",
        "        \"\"\"\n",
        "        for item in k_ranked:\n",
        "            if item == holdout:\n",
        "                return 1\n",
        "        return 0\n",
        "\n",
        "    def eval_rating(self, idx, test_ratings, test_negatives, K, model):\n",
        "        \"\"\"\n",
        "        holdout(df_test의 item)이 K순위 내에 있는지 평가하는 함수\n",
        "        \"\"\"\n",
        "        items = test_negatives[idx]      # negative items [neg_item_id, ... ] (1,100)\n",
        "        user_idx = test_ratings[idx][0]  # [user_id, item_id][0]\n",
        "        holdout = test_ratings[idx][1]   # [user_id, item_id][1]\n",
        "        items.append(holdout)            # holdout 추가 [neg_item_id, ..., holdout] (1,101)\n",
        "\n",
        "        # prediction\n",
        "        predict_user = np.full(len(items), user_idx, dtype='int32').reshape(-1, 1)  # [[user_id], ...], (101, 1)\n",
        "        np_items = np.array(items).reshape(-1, 1)                                   # [[item_id], ... ], (101, 1)\n",
        "\n",
        "        predictions = model.predict([predict_user, np_items])\n",
        "        predictions = predictions.flatten().tolist()\n",
        "        item_to_pre_score = {item:pre for item, pre in zip(items, predictions)}\n",
        "\n",
        "        # 점수가 높은 상위 k개 아이템 리스트\n",
        "        k_ranked = heapq.nlargest(K, item_to_pre_score, key=item_to_pre_score.get)\n",
        "\n",
        "        # holdout이 상위 K 순위에 포함 되는지 체크\n",
        "        # {1:포함, 0:포함x}\n",
        "        hits = self.get_hits(k_ranked, holdout)\n",
        "\n",
        "        return hits\n",
        "\n",
        "    def evaluate_top_k(self, df_neg, df_test, model, K=10):\n",
        "        \"\"\"\n",
        "        TOP-K metric을 사용해 모델을 평가하는 함수\n",
        "        \"\"\"\n",
        "        hits = []\n",
        "        test_u = df_test['user_id'].values.tolist()\n",
        "        test_i = df_test['item_id'].values.tolist()\n",
        "\n",
        "        test_ratings = list(zip(test_u, test_i))\n",
        "        df_neg = df_neg.drop(df_neg.columns[0], axis=1)\n",
        "        test_negatives = df_neg.values.tolist()  # [[(user_id, item_id=holdout)], neg_item,... ] (1,100)\n",
        "\n",
        "        # user 샘플링\n",
        "        sample_idx_lst = np.random.choice(len(test_ratings), int(len(test_ratings) * 0.3))\n",
        "        for user_idx in sample_idx_lst:  # 전체 사용: range(len(test_ratings))\n",
        "\n",
        "            hitrate = self.eval_rating(user_idx, test_ratings, test_negatives, K, model)\n",
        "            hits.append(hitrate)  # ex. [1,0,1,1,0,...] (1, df_test.shape[0])\n",
        "\n",
        "        return hits\n"
      ],
      "metadata": {
        "id": "s0H_7LgBwdgh"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "GMF"
      ],
      "metadata": {
        "id": "BvNc1F1owsWz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GMP:\n",
        "\n",
        "    def __init__(self, user_num, item_num):\n",
        "\n",
        "        latent_features = 8\n",
        "\n",
        "        # User embedding\n",
        "        user = Input(shape=(1,), dtype='int32')\n",
        "        user_embedding = Embedding(user_num, latent_features, input_length=user.shape[1])(user)\n",
        "        user_embedding = Flatten()(user_embedding)\n",
        "\n",
        "        # Item embedding\n",
        "        item = Input(shape=(1,), dtype='int32')\n",
        "        item_embedding = Embedding(item_num, latent_features, input_length=item.shape[1])(item)\n",
        "        item_embedding = Flatten()(item_embedding)\n",
        "\n",
        "        # Merge\n",
        "        concatenated = Multiply()([user_embedding, item_embedding])\n",
        "\n",
        "        # Output\n",
        "        output_layer = Dense(1, kernel_initializer='lecun_uniform', name='output_layer')(concatenated) # 1,1 / h(8,1)초기화\n",
        "\n",
        "        # Model\n",
        "        self.model = Model([user, item], output_layer)\n",
        "        self.model.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "    def get_model(self):\n",
        "        model = self.model\n",
        "        return model"
      ],
      "metadata": {
        "id": "kXBIOtFOwTvS"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MLP"
      ],
      "metadata": {
        "id": "an8UH4K0w7-B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP:\n",
        "\n",
        "    def __init__(self, user_num, item_num):\n",
        "\n",
        "        # User embedding\n",
        "        user = Input(shape=(1,), dtype='int32')\n",
        "        user_embedding = Embedding(user_num, 32, input_length=user.shape[1])(user)\n",
        "        user_embedding = Flatten()(user_embedding)\n",
        "\n",
        "        # Item embedding\n",
        "        item = Input(shape=(1,), dtype='int32')\n",
        "        item_embedding = Embedding(item_num, 32, input_length=item.shape[1])(item)\n",
        "        item_embedding = Flatten()(item_embedding)\n",
        "\n",
        "        # Merge\n",
        "        concatenated = Concatenate()([user_embedding, item_embedding])\n",
        "        dropout = Dropout(rate=0.2)(concatenated)\n",
        "\n",
        "        # Layer1\n",
        "        layer_1 = Dense(units=64, activation='relu', name='layer1')(dropout)  # (64,1)\n",
        "        dropout1 = Dropout(rate=0.2, name='dropout1')(layer_1)                # (64,1)\n",
        "        batch_norm1 = BatchNormalization(name='batch_norm1')(dropout1)        # (64,1)\n",
        "\n",
        "        # Layer2\n",
        "        layer_2 = Dense(units=32, activation='relu', name='layer2')(batch_norm1)  # (32,1)\n",
        "        dropout2 = Dropout(rate=0.2, name='dropout2')(layer_2)                    # (32,1)\n",
        "        batch_norm2 = BatchNormalization(name='batch_norm2')(dropout2)            # (32,1)\n",
        "\n",
        "        # Layer3\n",
        "        layer_3 = Dense(units=16, activation='relu', name='layer3')(batch_norm2)  # (16,1)\n",
        "\n",
        "        # Layer4\n",
        "        layer_4 = Dense(units=8, activation='relu', name='layer4')(layer_3)  # (8,1)\n",
        "\n",
        "        # Output\n",
        "        output_layer = Dense(1, kernel_initializer='lecun_uniform', name='output_layer')(layer_4)  # (1,1) / h(8,1)초기화\n",
        "\n",
        "        # Model\n",
        "        self.model = Model([user, item], output_layer)\n",
        "        self.model.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "    def get_model(self):\n",
        "        model = self.model\n",
        "        return model"
      ],
      "metadata": {
        "id": "RDgH94fqwu-u"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "NeuralMF"
      ],
      "metadata": {
        "id": "xmlBuuDAw-4C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuMF:\n",
        "\n",
        "    def __init__(self, user_num, item_num):\n",
        "\n",
        "        latent_features = 8\n",
        "\n",
        "        # Input\n",
        "        user = Input(shape=(1,), dtype='int32')\n",
        "        item = Input(shape=(1,), dtype='int32')\n",
        "\n",
        "        # User embedding for GMF\n",
        "        gmf_user_embedding = Embedding(user_num, latent_features, input_length=user.shape[1])(user)\n",
        "        gmf_user_embedding = Flatten()(gmf_user_embedding)\n",
        "\n",
        "        # Item embedding for GMF\n",
        "        gmf_item_embedding = Embedding(item_num, latent_features, input_length=item.shape[1])(item)\n",
        "        gmf_item_embedding = Flatten()(gmf_item_embedding)\n",
        "\n",
        "        # User embedding for MLP\n",
        "        mlp_user_embedding = Embedding(user_num, 32, input_length=user.shape[1])(user)\n",
        "        mlp_user_embedding = Flatten()(mlp_user_embedding)\n",
        "\n",
        "        # Item embedding for MLP\n",
        "        mlp_item_embedding = Embedding(item_num, 32, input_length=item.shape[1])(item)\n",
        "        mlp_item_embedding = Flatten()(mlp_item_embedding)\n",
        "\n",
        "        # GMF layers\n",
        "        gmf_mul =  Multiply()([gmf_user_embedding, gmf_item_embedding])\n",
        "\n",
        "        # MLP layers\n",
        "        mlp_concat = Concatenate()([mlp_user_embedding, mlp_item_embedding])\n",
        "        mlp_dropout = Dropout(0.2)(mlp_concat)\n",
        "\n",
        "        # Layer1\n",
        "        mlp_layer_1 = Dense(units=64, activation='relu', name='mlp_layer1')(mlp_dropout)  # (64,1)\n",
        "        mlp_dropout1 = Dropout(rate=0.2, name='dropout1')(mlp_layer_1)                    # (64,1)\n",
        "        mlp_batch_norm1 = BatchNormalization(name='batch_norm1')(mlp_dropout1)            # (64,1)\n",
        "\n",
        "        # Layer2\n",
        "        mlp_layer_2 = Dense(units=32, activation='relu', name='mlp_layer2')(mlp_batch_norm1)  # (32,1)\n",
        "        mlp_dropout2 = Dropout(rate=0.2, name='dropout2')(mlp_layer_2)                        # (32,1)\n",
        "        mlp_batch_norm2 = BatchNormalization(name='batch_norm2')(mlp_dropout2)                # (32,1)\n",
        "\n",
        "        # Layer3\n",
        "        mlp_layer_3 = Dense(units=16, activation='relu', name='mlp_layer3')(mlp_batch_norm2)  # (16,1)\n",
        "\n",
        "        # Layer4\n",
        "        mlp_layer_4 = Dense(units=8, activation='relu', name='mlp_layer4')(mlp_layer_3)       # (8,1)\n",
        "\n",
        "        # merge GMF + MLP\n",
        "        merged_vector = tf.keras.layers.concatenate([gmf_mul, mlp_layer_4])\n",
        "        \n",
        "        # Output layer\n",
        "        output_layer = Dense(1, kernel_initializer='lecun_uniform', name='output_layer')(merged_vector) # 1,1 / h(8,1)초기화\n",
        "\n",
        "        # Model\n",
        "        self.model = Model([user, item], output_layer)\n",
        "        self.model.compile(optimizer= 'adam', loss= 'binary_crossentropy')\n",
        "\n",
        "    def get_model(self):\n",
        "        model = self.model\n",
        "        return model\n"
      ],
      "metadata": {
        "id": "YH3uMTufw6Wx"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Run:\n",
        "\n",
        "    def __init__(self):\n",
        "\n",
        "        # data 로드\n",
        "        loader = Loader()\n",
        "\n",
        "        print('start data load..')\n",
        "\n",
        "        num_neg = 4\n",
        "        uids, iids, self.df_train, self.df_test, \\\n",
        "        self.df_neg, self.users, self.items, item_lookup = loader.load_dataset()\n",
        "        user_input, item_input, labels = loader.get_train_instances(uids, iids, num_neg, len(self.items))\n",
        "\n",
        "        print('end data load..')\n",
        "\n",
        "        # input data 준비\n",
        "        user_data_shuff, item_data_shuff, label_data_shuff = shuffle(user_input, item_input, labels)\n",
        "        self.user_data_shuff = np.array(user_data_shuff).reshape(-1,1)\n",
        "        self.item_data_shuff = np.array(item_data_shuff).reshape(-1,1)\n",
        "        self.label_data_shuff = np.array(label_data_shuff).reshape(-1,1)\n",
        "\n",
        "    def run(self):\n",
        "\n",
        "        nmf = GMP(len(self.users), len(self.items))  # Neural Collaborative Filtering\n",
        "        self.model = nmf.get_model()\n",
        "        self.model.fit([self.user_data_shuff, self.item_data_shuff], self.label_data_shuff, epochs=20,\n",
        "                       batch_size=256, verbose=1)\n",
        "\n",
        "        return self.model\n",
        "\n",
        "    def calculate_top_k_metric(self):\n",
        "        metric = Metric()\n",
        "        hit_lst = metric.evaluate_top_k(self.df_neg, self.df_test, self.model, K=10)\n",
        "        hit = np.mean(hit_lst)\n",
        "\n",
        "        return hit\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    ncf = Run()\n",
        "    model = ncf.run()\n",
        "\n",
        "    # top-k metric\n",
        "    top_k_metric = ncf.calculate_top_k_metric()\n",
        "    print('metric:', top_k_metric)\n",
        "\n",
        "    # user 한 명에 대한 prediction 예시\n",
        "    user_id = 0\n",
        "    user_candidate_item = np.array([134, 6783, 27888, 8362, 25]).reshape(-1, 1)\n",
        "    user_input = np.full(len(user_candidate_item), user_id, dtype='int32').reshape(-1, 1)\n",
        "\n",
        "    predictions = model.predict([user_input, user_candidate_item])\n",
        "    predictions = predictions.flatten().tolist()\n",
        "    item_to_pre_score = {item[0]: pre for item, pre in zip(user_candidate_item, predictions)}  # 후보 아이템 별 예측값\n",
        "    item_to_pre_score = dict(sorted(item_to_pre_score.items(), key=lambda x: x[1], reverse=True))\n",
        "\n",
        "    recommend_item_lst = list(item_to_pre_score.keys())\n",
        "    print('recommend:', recommend_item_lst)"
      ],
      "metadata": {
        "id": "dWSAU1a4xDov",
        "outputId": "c2f6aa8a-5c48-4519-8b3a-7ebe6cdd3449",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "start data load..\n",
            "end data load..\n",
            "Epoch 1/20\n",
            "31327/92194 [=========>....................] - ETA: 22:44 - loss: 0.4442"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9xULlfbJCSe_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r-ebvPJ1CSf9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qiRmMmRTChIe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XWqwYKi3JJ-E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fR1HbxCEJKBK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q2zOpIchJYld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "36q3QNLT7QC7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n9krlRbn7XXp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0G31yzNu7e8A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4BAhudLcxMZd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2Yalw_Ep0YkO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AMiXOQTX0fzq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xiXQnyZa0nUM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}